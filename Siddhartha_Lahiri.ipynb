{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe5f41c",
   "metadata": {},
   "source": [
    "# Lending Club Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "e6f25306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing core libraries required for the case study\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sea\n",
    "import datetime as dt\n",
    "\n",
    "# Setting this to true prints debug text like stats and counts\n",
    "debug = True\n",
    "\n",
    "# Taking two options\n",
    "# - impute = True - Will replace empty rows with median values\n",
    "# - impute = False - Will drop rows with empty values\n",
    "impute = True\n",
    "\n",
    "\n",
    "# Utility function to take a snapshot of the csv locally just to validate the outputs\n",
    "def snapshot_data(df, snapshot_name): \n",
    "    if debug == True:\n",
    "        print(df.shape)\n",
    "        df.to_csv('./.data/snapshot.'+ snapshot_name +'.loan.csv')  \n",
    "\n",
    "# Setting max rows settings to 200 to display all the summary data\n",
    "pd.set_option(\"display.max_rows\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f365196",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "2b363dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the complete dataset into variable df\n",
    "df_loan = pd.read_csv('./.data/loan.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "0f3f6c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                0\n",
      "member_id                         0\n",
      "loan_amnt                         0\n",
      "funded_amnt                       0\n",
      "funded_amnt_inv                   0\n",
      "                              ...  \n",
      "tax_liens                        39\n",
      "tot_hi_cred_lim               39717\n",
      "total_bal_ex_mort             39717\n",
      "total_bc_limit                39717\n",
      "total_il_high_credit_limit    39717\n",
      "Length: 111, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print summary of Nulls, Blanks in the dataset\n",
    "if debug == True:\n",
    "    print(df_loan.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d51550",
   "metadata": {},
   "source": [
    "## Step1 - Dropping Rows - where loan_status = \"Current\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "9221696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rows where loan_stats=Current are the data where the loan repayment is currently in progress\n",
    "# The loans which are currently in progress will not contribute to decisions \n",
    "# of default or pass as it's difficult to predict the outcome\n",
    "#\n",
    "# Dropping the rwos early as, dropping all Currrent rows introduces NA columns which can be easily dropped\n",
    "rows_before = len(df_loan)\n",
    "df_clean = df_loan[df_loan['loan_status'] != \"Current\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "7d64d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped =  1140\n",
      "Percentage of rows dropped =  2.87 %\n"
     ]
    }
   ],
   "source": [
    "# Print current data statistics after dropping rows with loan_status \"CURRENT\"\n",
    "rows_after = len(df_clean)\n",
    "if debug == True:\n",
    "    print(\"Number of rows dropped = \", (rows_before - rows_after))\n",
    "    print(\"Percentage of rows dropped = \", round((rows_before - rows_after)/rows_before*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61611a50",
   "metadata": {},
   "source": [
    "## Step2 - Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "a85a29e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 111)\n"
     ]
    }
   ],
   "source": [
    "# Print the initial shape of the array before dropping columns\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "fb459ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns which is unique id in nature. They dont contribute to loan analysis\n",
    "df_clean = df_clean.drop(['id','member_id'],  axis=1)\n",
    "\n",
    "# Dropping text/description columns which wont contribute to overall analysis\n",
    "# These are names of establishment etc which will not contribute to loan pass or failure\n",
    "# THe URL column is a static link with id as the attribute. Its a redundant column\n",
    "df_clean = df_clean.drop(['url', 'emp_title', 'desc', 'title'],  axis=1)\n",
    "\n",
    "# Dropping column sub_grade as the current analysis will limit to Grade only\n",
    "df_clean = df_clean.drop(['sub_grade'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "22c7cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns which refer to behavoural data of customer post loan approval \n",
    "# Behaviour data of the customers are captured post the loan approval\n",
    "# The data is not available at the time of loan approval and thus cannot be used for calculations\n",
    "df_clean = df_clean.drop(['delinq_2yrs', 'earliest_cr_line', \n",
    "                          'inq_last_6mths', 'open_acc', 'pub_rec', \n",
    "                          'revol_bal', 'revol_util', 'total_acc', \n",
    "                          'out_prncp', 'out_prncp_inv', 'total_pymnt', \n",
    "                          'total_pymnt_inv', 'total_rec_prncp', \n",
    "                          'total_rec_int', 'total_rec_late_fee', 'recoveries', \n",
    "                          'collection_recovery_fee', 'last_pymnt_d', \n",
    "                          'last_pymnt_amnt', 'last_credit_pull_d', \n",
    "                          'application_type'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "aba52016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 83)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of dataframe post dropping behaviour, redundant and other columns which dont contribute to analysis\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "3c40ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with all values as NA ['next_pymnt_d', 'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit']\n"
     ]
    }
   ],
   "source": [
    "# Dropping all columns whose all the values are NA\n",
    "# Print all NA columns for verification\n",
    "if debug == True:\n",
    "    print(\"Columns with all values as NA\", df_clean.columns[df_clean.isna().all()].tolist())\n",
    "\n",
    "# Dropping all the columns whose all the records are NaN or Null\n",
    "df_clean = df_clean.dropna(axis='columns', how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "863f9020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 28)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of dataframe post dropping behaviour, redundant and other columns which dont contribute to analysis\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "d35350b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns with all zero values\n",
    "df_clean = df_clean.loc[:, (df_clean != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "132295b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pymnt_plan\n",
      "initial_list_status\n",
      "collections_12_mths_ex_med\n",
      "policy_code\n",
      "chargeoff_within_12_mths\n",
      "tax_liens\n"
     ]
    }
   ],
   "source": [
    "# Function to Drop all columns who have constant values (ignoring NA value)\n",
    "# Example most of the columns is 1 and rest is NA, the column will be dropped\n",
    "# If we have 1,2 and NA, the column wont be dropped\n",
    "def drop_constant_columns(df):\n",
    "    for c in df.columns:\n",
    "        if df[c].nunique(dropna=True) == 1:\n",
    "            if debug == True:\n",
    "                print(c)\n",
    "            df = df.drop(c, axis=1)\n",
    "    return df\n",
    "\n",
    "# Drop all constant columns from df1 (definition of constant is constant value across the rows, this ignores Na values)\n",
    "df_clean = drop_constant_columns(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "ace012ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of dataframe post dropping columns having constant values. \n",
    "# This includes columns which has constant + NA values as well\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "17934b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mths_since_last_delinq\n",
      "mths_since_last_record\n"
     ]
    }
   ],
   "source": [
    "# Function which checks the amount of empty values in a dataframe and \n",
    "# drops the column if the amount of empty values is more than 65%\n",
    "# 60% is the threshhold percentage which decides imputing vs dropping \n",
    "def drop_mostly_empty_columns(df):\n",
    "    total_rows = len(df)\n",
    "    for c in df.columns:\n",
    "        # Drop columns whose mean na values exceed 65%\n",
    "        if df[c].isna().mean().round(2) >= 0.65:\n",
    "            if debug == True:\n",
    "                print(c)\n",
    "            df = df.drop(c, axis=1)\n",
    "    return df\n",
    "df_clean = drop_mostly_empty_columns(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "7b54e07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 18)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the dataframe after dropping columns whose values are empty = more than 65%\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d367a812",
   "metadata": {},
   "source": [
    "## Step3 - Convert the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "56a612e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns loan_amnt and funded_amnt as flot64\n",
    "df_clean = df_clean.astype({'loan_amnt':'float','funded_amnt':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "9f049912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the term column into an integer from a string\n",
    "df_clean['term'] = df_clean['term'].apply(lambda x : int(x[:-7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "9c61fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert int_rate to  float by removing the \"%\" character\n",
    "df_clean['int_rate'] = df_clean['int_rate'].apply(lambda x : float(x[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "c7fcc0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt\n",
      "funded_amnt\n",
      "funded_amnt_inv\n",
      "int_rate\n",
      "dti\n"
     ]
    }
   ],
   "source": [
    "# Round off the values of key float fields to 2 decimal place\n",
    "# all int_rate and dti already limited to 2 edcimal\n",
    "for c in ['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'int_rate', 'dti']:\n",
    "    if debug == True:\n",
    "        print(c)\n",
    "    df_clean[c] = df_clean[c].apply(lambda x: round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "17bba559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the loan_status to boolean column. \"Fully-Paid is True and Charged Off is False\"\n",
    "# Added a function instead of lambda because, if this is accidentally re-run on a boolean column, the logic broke\n",
    "# Now it will only convert to boolean if the column is a string and has the two specific values\n",
    "def convert_loan_status_to_boolean(x):\n",
    "    if x == \"Fully Paid\":\n",
    "        return True\n",
    "    elif x == \"Charged Off\":\n",
    "        return False\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_clean['loan_status'] = df_clean['loan_status'].apply(lambda x: convert_loan_status_to_boolean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "ad26d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the column issue_d from string object to DateTime\n",
    "df_clean['issue_d'] = pd.to_datetime(df_clean['issue_d'], format='%b-%y')\n",
    "\n",
    "# Adding additional column for Year and Month for analysis extrating Year and Month from issue_d\n",
    "df_clean['issue_y'] = pd.DatetimeIndex(df_clean['issue_d']).year\n",
    "df_clean['issue_m'] = pd.DatetimeIndex(df_clean['issue_d']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "41009408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the dataframe after reformatting the columns datatypes\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02694d24",
   "metadata": {},
   "source": [
    "## Step 4 - Identify columns with blank values which need to be imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "72ba1219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_length 2.68 %\n",
      "pub_rec_bankruptcies 1.81 %\n"
     ]
    }
   ],
   "source": [
    "# Identify columns who have blank values and what percentage of total values are there blanks. \n",
    "# These values may need to be imputed\n",
    "for c in df_clean.columns[df_clean.isna().any()].tolist():\n",
    "    print(c, round(len(df_clean[df_clean[c].isna()]) / len(df_clean) * 100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a351d",
   "metadata": {},
   "source": [
    "Here two kinds of decision can be taken\n",
    "* **Option 1** - Drop the rows with blank values\n",
    "* **Option 2** - Impute the values with a median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "65f9b7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the current dimensions of the dataframe\n",
    "rows_before = len(df_clean)\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "a9d7a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this approach of taking both scenarios, we will evaluate the variation\n",
    "# If there is not much variation, we will take the drop approach as it will be more accurate as compared to imputing\n",
    "if impute == False:\n",
    "    # Drop rows with empty values in this scenario\n",
    "    # Since the percent of rows is very small, dropping the rows instead of imputing them\n",
    "    df_clean = df_clean[df_clean['emp_length'].notna()]\n",
    "    df_clean = df_clean[df_clean['pub_rec_bankruptcies'].notna()]\n",
    "else:\n",
    "    # Impute values with empty column values\n",
    "    # Since emp_length is a string, using mode to fill the empty values\n",
    "    df_clean['emp_length'].fillna(df_clean['emp_length'].mode()[0], inplace=True)\n",
    "    df_clean['pub_rec_bankruptcies'].fillna(df_clean['pub_rec_bankruptcies'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "14eb71e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 20)\n",
      "Number of rows dropped = , 0\n",
      "Percentage of rows dropped =  0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of the dataframe after dropping rows\n",
    "rows_after = len(df_clean)\n",
    "if debug == True:\n",
    "    print(df_clean.shape)\n",
    "    print(\"Number of rows dropped = ,\", (rows_before - rows_after))\n",
    "    print(\"Percentage of rows dropped = \", round((rows_before - rows_after)/rows_before*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "e8262b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10+ years    9521\n",
      "< 1 year     4508\n",
      "2 years      4291\n",
      "3 years      4012\n",
      "4 years      3342\n",
      "5 years      3194\n",
      "1 year       3169\n",
      "6 years      2168\n",
      "7 years      1711\n",
      "8 years      1435\n",
      "9 years      1226\n",
      "Name: emp_length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if debug == True:\n",
    "    print(df_clean['emp_length'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "8e84efc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    9521\n",
      "0     4508\n",
      "2     4291\n",
      "3     4012\n",
      "4     3342\n",
      "5     3194\n",
      "1     3169\n",
      "6     2168\n",
      "7     1711\n",
      "8     1435\n",
      "9     1226\n",
      "Name: emp_length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Converting emp_length to a string object explicitly as python id giving intermitent error of float\n",
    "#df_clean['emp_length'] = df_clean['emp_length'].apply(lambda x: str(x))\n",
    "\n",
    "# Converting emp_length to integer values\n",
    "# Converting <0 as 0 and 10+ as 10\n",
    "# Converting emp_length as numerical data to create more effective statistical analysis as compared to nominal values\n",
    "df_clean['emp_length'] = df_clean['emp_length'].replace({'< 1 year': 0, '2 years': 2, '3 years': 3, \n",
    "                                                         '7 years': 7, '4 years': 4, '5 years': 5, \n",
    "                                                         '1 year': 1, '6 years': 6, '8 years': 8, \n",
    "                                                         '9 years': 9,  '10+ years': 10})\n",
    "\n",
    "if debug == True:\n",
    "    print(df_clean['emp_length'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "1cee0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38577 entries, 0 to 39716\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   loan_amnt             38577 non-null  float64       \n",
      " 1   funded_amnt           38577 non-null  float64       \n",
      " 2   funded_amnt_inv       38577 non-null  float64       \n",
      " 3   term                  38577 non-null  int64         \n",
      " 4   int_rate              38577 non-null  float64       \n",
      " 5   installment           38577 non-null  float64       \n",
      " 6   grade                 38577 non-null  object        \n",
      " 7   emp_length            38577 non-null  int64         \n",
      " 8   home_ownership        38577 non-null  object        \n",
      " 9   annual_inc            38577 non-null  float64       \n",
      " 10  verification_status   38577 non-null  object        \n",
      " 11  issue_d               38577 non-null  datetime64[ns]\n",
      " 12  loan_status           38577 non-null  bool          \n",
      " 13  purpose               38577 non-null  object        \n",
      " 14  zip_code              38577 non-null  object        \n",
      " 15  addr_state            38577 non-null  object        \n",
      " 16  dti                   38577 non-null  float64       \n",
      " 17  pub_rec_bankruptcies  38577 non-null  float64       \n",
      " 18  issue_y               38577 non-null  int64         \n",
      " 19  issue_m               38577 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), float64(8), int64(4), object(6)\n",
      "memory usage: 5.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing column info to analyse missing values, empty values in a column\n",
    "if debug == True:\n",
    "    print(df_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "0a90149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always take one final snapshot - Temp file\n",
    "if debug == True:\n",
    "    df_clean.to_csv('./.data/snapshot.clean.loan.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790310ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
