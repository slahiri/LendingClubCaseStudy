{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe5f41c",
   "metadata": {},
   "source": [
    "# Lending Club Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e6f25306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing core libraries required for the case study\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sea\n",
    "import datetime as dt\n",
    "\n",
    "debug = True\n",
    "# Utility function to take a snapshot of the csv locally just to validate the outputs\n",
    "def snapshot_data(df, snapshot_name): \n",
    "    if debug == True:\n",
    "        print(df.shape)\n",
    "        df.to_csv('./.data/snapshot.'+ snapshot_name +'.loan.csv')  \n",
    "\n",
    "# Setting max rows settings to 200 to display all the summary data\n",
    "pd.set_option(\"display.max_rows\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f365196",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2b363dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the complete dataset into variable df\n",
    "df_loan = pd.read_csv('./.data/loan.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "148f2aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                0\n",
      "member_id                         0\n",
      "loan_amnt                         0\n",
      "funded_amnt                       0\n",
      "funded_amnt_inv                   0\n",
      "                              ...  \n",
      "tax_liens                        39\n",
      "tot_hi_cred_lim               39717\n",
      "total_bal_ex_mort             39717\n",
      "total_bc_limit                39717\n",
      "total_il_high_credit_limit    39717\n",
      "Length: 111, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print summary of Nulls, Blanks in the dataset\n",
    "if debug == True:\n",
    "    print(df_loan.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d51550",
   "metadata": {},
   "source": [
    "## Step1 - Dropping Rows - where loan_status = \"Current\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9221696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rows where loan_stats=Current are the data where the loan repayment is currently in progress\n",
    "# The loans which are currently in progress will not contribute to decisions \n",
    "# of default or pass as it's difficult to predict the outcome\n",
    "#\n",
    "# Dropping the rwos early as, dropping all Currrent rows introduces NA columns which can be easily dropped\n",
    "rows_before = len(df_loan)\n",
    "df_clean = df_loan[df_loan['loan_status'] != \"Current\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7d64d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped =  1140\n",
      "Percentage of rows dropped =  2.87 %\n"
     ]
    }
   ],
   "source": [
    "# Print current data statistics after dropping rows with loan_status \"CURRENT\"\n",
    "rows_after = len(df_clean)\n",
    "if debug == True:\n",
    "    print(\"Number of rows dropped = \", (rows_before - rows_after))\n",
    "    print(\"Percentage of rows dropped = \", round((rows_before - rows_after)/rows_before*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61611a50",
   "metadata": {},
   "source": [
    "## Step2 - Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4b911260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 111)\n"
     ]
    }
   ],
   "source": [
    "# Print the initial shape of the array before dropping columns\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fb459ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns which is unique id in nature. They dont contribute to loan analysis\n",
    "df_clean = df_clean.drop(['id','member_id'],  axis=1)\n",
    "\n",
    "# Dropping text/description columns which wont contribute to overall analysis\n",
    "# These are names of establishment etc which will not contribute to loan pass or failure\n",
    "# THe URL column is a static link with id as the attribute. Its a redundant column\n",
    "df_clean = df_clean.drop(['url', 'emp_title', 'desc', 'title'],  axis=1)\n",
    "\n",
    "# Dropping column sub_grade as the current analysis will limit to Grade only\n",
    "df_clean = df_clean.drop(['sub_grade'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "22c7cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns which refer to behavoural data of customer post loan approval \n",
    "# Behaviour data of the customers are captured post the loan approval\n",
    "# The data is not available at the time of loan approval and thus cannot be used for calculations\n",
    "df_clean = df_clean.drop(['delinq_2yrs', 'earliest_cr_line', \n",
    "                          'inq_last_6mths', 'open_acc', 'pub_rec', \n",
    "                          'revol_bal', 'revol_util', 'total_acc', \n",
    "                          'out_prncp', 'out_prncp_inv', 'total_pymnt', \n",
    "                          'total_pymnt_inv', 'total_rec_prncp', \n",
    "                          'total_rec_int', 'total_rec_late_fee', 'recoveries', \n",
    "                          'collection_recovery_fee', 'last_pymnt_d', \n",
    "                          'last_pymnt_amnt', 'last_credit_pull_d', \n",
    "                          'application_type'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "336b86d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 83)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of dataframe post dropping behaviour, redundant and other columns which dont contribute to analysis\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3c40ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with all values as NA ['next_pymnt_d', 'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit']\n"
     ]
    }
   ],
   "source": [
    "# Dropping all columns whose all the values are NA\n",
    "# Print all NA columns for verification\n",
    "if debug == True:\n",
    "    print(\"Columns with all values as NA\", df_clean.columns[df_clean.isna().all()].tolist())\n",
    "\n",
    "# Dropping all the columns whose all the records are NaN or Null\n",
    "df_clean = df_clean.dropna(axis='columns', how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "aba85ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 28)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of dataframe post dropping behaviour, redundant and other columns which dont contribute to analysis\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d35350b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns with all zero values\n",
    "df_clean = df_clean.loc[:, (df_clean != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "132295b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pymnt_plan\n",
      "initial_list_status\n",
      "collections_12_mths_ex_med\n",
      "policy_code\n",
      "chargeoff_within_12_mths\n",
      "tax_liens\n"
     ]
    }
   ],
   "source": [
    "# Function to Drop all columns who have constant values (ignoring NA value)\n",
    "# Example most of the columns is 1 and rest is NA, the column will be dropped\n",
    "# If we have 1,2 and NA, the column wont be dropped\n",
    "def drop_constant_columns(df):\n",
    "    for c in df.columns:\n",
    "        if df[c].nunique(dropna=True) == 1:\n",
    "            if debug == True:\n",
    "                print(c)\n",
    "            df = df.drop(c, axis=1)\n",
    "    return df\n",
    "\n",
    "# Drop all constant columns from df1 (definition of constant is constant value across the rows, this ignores Na values)\n",
    "df_clean = drop_constant_columns(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f8cf12b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of dataframe post dropping columns having constant values. \n",
    "# This includes columns which has constant + NA values as well\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "17934b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mths_since_last_delinq\n",
      "mths_since_last_record\n"
     ]
    }
   ],
   "source": [
    "# Function which checks the amount of empty values in a dataframe and \n",
    "# drops the column if the amount of empty values is more than 65%\n",
    "# 60% is the threshhold percentage which decides imputing vs dropping \n",
    "def drop_mostly_empty_columns(df):\n",
    "    total_rows = len(df)\n",
    "    for c in df.columns:\n",
    "        # Drop columns whose mean na values exceed 65%\n",
    "        if df[c].isna().mean().round(2) >= 0.65:\n",
    "            if debug == True:\n",
    "                print(c)\n",
    "            df = df.drop(c, axis=1)\n",
    "    return df\n",
    "df_clean = drop_mostly_empty_columns(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7b54e07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 18)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the dataframe after dropping columns whose values are empty = more than 65%\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d367a812",
   "metadata": {},
   "source": [
    "## Step3 - Convert the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "56a612e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns loan_amnt and funded_amnt as flot64\n",
    "df_clean = df_clean.astype({'loan_amnt':'float','funded_amnt':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9f049912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the term column into an integer from a string\n",
    "df_clean['term'] = df_clean['term'].apply(lambda x : int(x[:-7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9c61fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert int_rate to  float by removing the \"%\" character\n",
    "df_clean['int_rate'] = df_clean['int_rate'].apply(lambda x : float(x[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "17bba559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the loan_status to boolean column. \"Fully-Paid is True and Charged Off is False\"\n",
    "# Added a function instead of lambda because, if this is accidentally re-run on a boolean column, the logic broke\n",
    "# Now it will only convert to boolean if the column is a string and has the two specific values\n",
    "def convert_loan_status_to_boolean(x):\n",
    "    if x == \"Fully Paid\":\n",
    "        return True\n",
    "    elif x == \"Charged Off\":\n",
    "        return False\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_clean['loan_status'] = df_clean['loan_status'].apply(lambda x: convert_loan_status_to_boolean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ad26d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the column issue_d from string object to DateTime\n",
    "df_clean['issue_d'] = pd.to_datetime(df_clean['issue_d'], format='%b-%y')\n",
    "\n",
    "# Adding additional column for Year and Month for analysis extrating Year and Month from issue_d\n",
    "df_clean['issue_y'] = pd.DatetimeIndex(df_clean['issue_d']).year\n",
    "df_clean['issue_m'] = pd.DatetimeIndex(df_clean['issue_d']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc560cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "41009408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the dataframe after reformatting the columns datatypes\n",
    "if debug == True:\n",
    "    print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02694d24",
   "metadata": {},
   "source": [
    "## Step 4 - Identify columns with blank values which need to be imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "72ba1219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_length 2.68 %\n",
      "pub_rec_bankruptcies 1.81 %\n"
     ]
    }
   ],
   "source": [
    "# Identify columns who have blank values and what percentage of total values are there blanks. \n",
    "# These values may need to be imputed\n",
    "for c in df_clean.columns[df_clean.isna().any()].tolist():\n",
    "    print(c, round(len(df_clean[df_clean[c].isna()]) / len(df_clean) * 100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a351d",
   "metadata": {},
   "source": [
    "Here two kinds of decision can be taken\n",
    "* **Option 1** - Drop the rows with blank values\n",
    "* **Option 2** - Impute the values with a median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cc8eaefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38577, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the current dimensions of the dataframe\n",
    "rows_before = len(df_clean)\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a9d7a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the percent of rows is very small, dropping the rows instead of imputing them\n",
    "df_clean = df_clean[df_clean['emp_length'].notna()]\n",
    "df_clean = df_clean[df_clean['pub_rec_bankruptcies'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "160bcdf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36847, 20)\n",
      "Number of rows dropped = , 1730\n",
      "Percentage of rows dropped =  4.48 %\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of the dataframe after dropping rows\n",
    "rows_after = len(df_clean)\n",
    "print(df_clean.shape)\n",
    "print(\"Number of rows dropped = ,\", (rows_before - rows_after))\n",
    "print(\"Percentage of rows dropped = \", round((rows_before - rows_after)/rows_before*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c331fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting emp_length to a string object explicitly as python id giving intermitent error of float\n",
    "df_clean['emp_length'] = df_clean['emp_length'].apply(lambda x: str(x))\n",
    "# Remove years keyword from the emp_lemgth column\n",
    "# Remove + and < characters\n",
    "# Consider 10 + as 10 and <1 as 1 for the sake of this analysis\n",
    "# This is because anything 10+ is represented as 10 + years, there is no distinct and unique value available\n",
    "# So replacing 10+ to 10 will not impact to the resolution of the data\n",
    "# Similarly replacing <1 to 1 will not impact the analysis as well\n",
    "df_clean['emp_length'] = df_clean['emp_length'].apply(lambda x: int(x.rstrip(\"year\").rstrip(\"years\").rstrip(\" \").rstrip(\"+\").lstrip(\"<\").lstrip()))\n",
    "# Will add a column later to bin the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e2bb5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will also try to use median to impute the values and compare both outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1cee0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36847 entries, 0 to 39680\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   loan_amnt             36847 non-null  float64       \n",
      " 1   funded_amnt           36847 non-null  float64       \n",
      " 2   funded_amnt_inv       36847 non-null  float64       \n",
      " 3   term                  36847 non-null  int64         \n",
      " 4   int_rate              36847 non-null  float64       \n",
      " 5   installment           36847 non-null  float64       \n",
      " 6   grade                 36847 non-null  object        \n",
      " 7   emp_length            36847 non-null  int64         \n",
      " 8   home_ownership        36847 non-null  object        \n",
      " 9   annual_inc            36847 non-null  float64       \n",
      " 10  verification_status   36847 non-null  object        \n",
      " 11  issue_d               36847 non-null  datetime64[ns]\n",
      " 12  loan_status           36847 non-null  bool          \n",
      " 13  purpose               36847 non-null  object        \n",
      " 14  zip_code              36847 non-null  object        \n",
      " 15  addr_state            36847 non-null  object        \n",
      " 16  dti                   36847 non-null  float64       \n",
      " 17  pub_rec_bankruptcies  36847 non-null  float64       \n",
      " 18  issue_y               36847 non-null  int64         \n",
      " 19  issue_m               36847 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), float64(8), int64(4), object(6)\n",
      "memory usage: 5.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing column info to analyse missing values, empty values in a column\n",
    "print(df_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0a90149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always take one final snapshot - Temp file\n",
    "df_clean.to_csv('./.data/snapshot.clean.loan.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c1ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b9c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
