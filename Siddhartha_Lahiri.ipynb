{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe5f41c",
   "metadata": {},
   "source": [
    "# Lending Club Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e6f25306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing core libraries required for the case study\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sea\n",
    "\n",
    "# Loading loan data from public google drive\n",
    "# Code referenced from https://stackoverflow.com/questions/56611698/pandas-how-to-read-csv-file-from-google-drive-public\n",
    "url = \"https://drive.google.com/file/d/1gHUGDYuGFd3paXvypwvDzGTe_HZSjILf/view?usp=sharing\"\n",
    "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "debug = False\n",
    "# Utility function to take a snapshot of the csv locally just to validate the outputs\n",
    "def snapshot_data(df, snapshot_name): \n",
    "    if debug == True:\n",
    "        print(df.shape)\n",
    "        df.to_csv('./data/snapshot.'+ snapshot_name +'.loan.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f365196",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2b363dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the complete dataset into variable df\n",
    "df_loan = pd.read_csv(url, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d51550",
   "metadata": {},
   "source": [
    "## Step1 - Dropping Rows - where loan_status = \"Current\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9221696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rows where loan_stats=Current are the data where the loan repayment is currently in progress\n",
    "# The loans which are currently in progress will not contribute to decisions \n",
    "# of default or pass as it's difficult to predict the outcome\n",
    "#\n",
    "# Dropping the rwos early as, dropping all Currrent rows introduces NA columns which can be easily dropped\n",
    "df_clean = df_clean[df_clean['loan_status'] != \"Current\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "39d81bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_data(df_clean,'step1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61611a50",
   "metadata": {},
   "source": [
    "## Step2 - Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fb459ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns which is unique id in nature. They dont contribute to loan analysis\n",
    "df_clean = df_loan.drop(['id','member_id'],  axis=1)\n",
    "\n",
    "# Dropping text/description columns which wont contribute to overall analysis\n",
    "# These are names of establishment etc which will not contribute to loan pass or failure\n",
    "# THe URL column is a static link with id as the attribute. Its a redundant column\n",
    "df_clean = df_clean.drop(['url', 'emp_title', 'desc', 'title'],  axis=1)\n",
    "\n",
    "# Dropping column sub_grade as the current analysis will limit to Grade only\n",
    "df_clean = df_clean.drop(['sub_grade'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "22c7cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns which refer to behavoural data of customer post loan approval \n",
    "# Behaviour data of the customers are captured post the loan approval\n",
    "# The data is not available at the time of loan approval and thus cannot be used for calculations\n",
    "df_clean = df_clean.drop(['delinq_2yrs', 'earliest_cr_line', \n",
    "                          'inq_last_6mths', 'open_acc', 'pub_rec', \n",
    "                          'revol_bal', 'revol_util', 'total_acc', \n",
    "                          'out_prncp', 'out_prncp_inv', 'total_pymnt', \n",
    "                          'total_pymnt_inv', 'total_rec_prncp', \n",
    "                          'total_rec_int', 'total_rec_late_fee', 'recoveries', \n",
    "                          'collection_recovery_fee', 'last_pymnt_d', \n",
    "                          'last_pymnt_amnt', 'last_credit_pull_d', \n",
    "                          'application_type'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3c40ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns whose all the values are NA\n",
    "# Print all NA columns for verification\n",
    "if debug == True:\n",
    "    print(\"Columns with all values as NA\", df_clean.columns[df_clean.isna().all()].tolist())\n",
    "\n",
    "# Dropping all the columns whose all the records are NaN or Null\n",
    "df_clean = df_clean.dropna(axis='columns', how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d35350b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns with all zero values\n",
    "df_clean = df_clean.loc[:, (df_clean != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "132295b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Drop all columns who have constant values (ignoring NA value)\n",
    "# Example most of the columns is 1 and rest is NA, the column will be dropped\n",
    "# If we have 1,2 and NA, the column wont be dropped\n",
    "def drop_constant_columns(df):\n",
    "    for c in df.columns:\n",
    "        if df[c].nunique(dropna=True) == 1:\n",
    "            if debug == True:\n",
    "                print(c)\n",
    "            df = df.drop(c, axis=1)\n",
    "    return df\n",
    "\n",
    "# Drop all constant columns from df1 (definition of constant is constant value across the rows, this ignores Na values)\n",
    "df_clean = drop_constant_columns(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "17934b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which checks the amount of empty values in a dataframe and \n",
    "# drops the column if the amount of empty values is more than 65%\n",
    "# 60% is the threshhold percentage which decides imputing vs dropping \n",
    "def drop_mostly_empty_columns(df):\n",
    "    total_rows = len(df)\n",
    "    for c in df.columns:\n",
    "        # Drop columns whose mean na values exceed 65%\n",
    "        if df[c].isna().mean().round(2) >= 0.65:\n",
    "            if debug == True:\n",
    "                print(c)\n",
    "            df = df.drop(c, axis=1)\n",
    "    return df\n",
    "df_clean = drop_mostly_empty_columns(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2ec21816",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_data(df_clean,'step2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d367a812",
   "metadata": {},
   "source": [
    "## Step3 - Convert the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "56a612e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns loan_amnt and funded_amnt as flot64\n",
    "df_clean = df_clean.astype({'loan_amnt':'float','funded_amnt':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "9f049912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the term column into an integer from a string\n",
    "df_clean['term'] = df_clean['term'].apply(lambda x : int(x[:-7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9c61fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert int_rate to  float by removing the \"%\" character\n",
    "df_clean['int_rate'] = df_clean['int_rate'].apply(lambda x : float(x[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2a077ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_data(df_clean,'step3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a2d4cc",
   "metadata": {},
   "source": [
    "## Step 4 - Identify columns with blank values which need to be imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "eb57e7d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_length 2.71 %\n",
      "pub_rec_bankruptcies 1.75 %\n"
     ]
    }
   ],
   "source": [
    "# Identify columns who have blank values and what percentage of total values are there blanks. \n",
    "# These values may need to be imputed\n",
    "for c in df_clean.columns[df_clean.isna().any()].tolist():\n",
    "    print(c, round(len(df_clean[df_clean[c].isna()]) / len(df_clean) * 100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "fbb973cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the percent of rows is very small, dropping the rows instead of imputing them\n",
    "df_clean = df_clean[df_clean['emp_length'].notna()]\n",
    "df_clean = df_clean[df_clean['pub_rec_bankruptcies'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3f9b16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_data(df_clean,'step4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86b338",
   "metadata": {},
   "source": [
    "## Step 5 - Converting the loan_status to boolean column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1348dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the loan_status to boolean column. \"Fully-Paid is True and Charged Off is False\"\n",
    "df_clean['loan_status'] = df_clean['loan_status'].apply(lambda x: True if x == 'Fully Paid' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "21337f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_data(df_clean,'step5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "1cee0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37945 entries, 0 to 39680\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   loan_amnt             37945 non-null  float64\n",
      " 1   funded_amnt           37945 non-null  float64\n",
      " 2   funded_amnt_inv       37945 non-null  float64\n",
      " 3   term                  37945 non-null  int64  \n",
      " 4   int_rate              37945 non-null  float64\n",
      " 5   installment           37945 non-null  float64\n",
      " 6   grade                 37945 non-null  object \n",
      " 7   emp_length            37945 non-null  object \n",
      " 8   home_ownership        37945 non-null  object \n",
      " 9   annual_inc            37945 non-null  float64\n",
      " 10  verification_status   37945 non-null  object \n",
      " 11  issue_d               37945 non-null  object \n",
      " 12  loan_status           37945 non-null  bool   \n",
      " 13  purpose               37945 non-null  object \n",
      " 14  zip_code              37945 non-null  object \n",
      " 15  addr_state            37945 non-null  object \n",
      " 16  dti                   37945 non-null  float64\n",
      " 17  pub_rec_bankruptcies  37945 non-null  float64\n",
      "dtypes: bool(1), float64(8), int64(1), object(8)\n",
      "memory usage: 5.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing column info to analyse missing values, empty values in a column\n",
    "print(df_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0a90149b",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './data/snapshot.clean.loan.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18672/862476799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Always take one final snapshot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/snapshot.clean.loan.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './data/snapshot.clean.loan.csv'"
     ]
    }
   ],
   "source": [
    "# Always take one final snapshot\n",
    "df_clean.to_csv('./data/snapshot.clean.loan.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
